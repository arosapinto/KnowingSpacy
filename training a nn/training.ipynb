{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we get starting with explaining how, it's worth taking a second to ask ourselves: Why would we want to update the model with our own examples? Why can't we just rely on pre-trained pipelines?\n",
    "\n",
    "Statistical models make predictions based on the examples they were trained on.\n",
    "\n",
    "You can usually make the model more accurate by showing it examples from your domain.\n",
    "\n",
    "You often also want to predict categories specific to your problem, so the model needs to learn about them.\n",
    "\n",
    "This is essential for text classification, very useful for entity recognition and a little less critical for tagging and parsing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "spaCy supports updating existing models with more examples, and training new models. If we're not starting with a trained pipeline, we first initialize the weights randomly.\n",
    "\n",
    "Next, spaCy calls nlp.update, which predicts a batch of examples with the current weights.\n",
    "\n",
    "The model then checks the predictions against the correct answers, and decides how to change the weights to achieve better predictions next time.\n",
    "\n",
    "Finally, we make a small correction to the current weights and move on to the next batch of examples.\n",
    "\n",
    "spaCy then continues calling nlp.update for each batch of examples in the data. During training, you usually want to make multiple passes over the data and train until the model stops improving."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How training works???\n",
    "\n",
    "\n",
    "1. Initialize the model weights randomly\n",
    "\n",
    "2. Predict a few examples with the current weights\n",
    "\n",
    "3. Compare prediction with true labels\n",
    "\n",
    "4. Calculate how to change weights to improve predictions\n",
    "\n",
    "5. Update weights slightly\n",
    "\n",
    "6. Go back to 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nlp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Test folder\\KnowingSpacy\\training a nn\\training.ipynb Cell 4'\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Test%20folder/KnowingSpacy/training%20a%20nn/training.ipynb#ch0000004?line=0'>1</a>\u001b[0m \u001b[39m###Training the entity recognizer\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Test%20folder/KnowingSpacy/training%20a%20nn/training.ipynb#ch0000004?line=1'>2</a>\u001b[0m \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Test%20folder/KnowingSpacy/training%20a%20nn/training.ipynb#ch0000004?line=2'>3</a>\u001b[0m \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Test%20folder/KnowingSpacy/training%20a%20nn/training.ipynb#ch0000004?line=3'>4</a>\u001b[0m \u001b[39m#The entity recognizer tags words and phrases in context\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Test%20folder/KnowingSpacy/training%20a%20nn/training.ipynb#ch0000004?line=4'>5</a>\u001b[0m \u001b[39m#Each token can only be part of one entity\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Test%20folder/KnowingSpacy/training%20a%20nn/training.ipynb#ch0000004?line=5'>6</a>\u001b[0m \u001b[39m#Examples need to come with context\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Test%20folder/KnowingSpacy/training%20a%20nn/training.ipynb#ch0000004?line=7'>8</a>\u001b[0m doc \u001b[39m=\u001b[39m nlp(\u001b[39m\"\u001b[39m\u001b[39miPhone X is coming\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Test%20folder/KnowingSpacy/training%20a%20nn/training.ipynb#ch0000004?line=8'>9</a>\u001b[0m doc\u001b[39m.\u001b[39ments \u001b[39m=\u001b[39m [Span(doc, \u001b[39m0\u001b[39m, \u001b[39m2\u001b[39m, label\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mGADGET\u001b[39m\u001b[39m\"\u001b[39m)]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Test%20folder/KnowingSpacy/training%20a%20nn/training.ipynb#ch0000004?line=10'>11</a>\u001b[0m \u001b[39m#Texts with no entities are also important\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'nlp' is not defined"
     ]
    }
   ],
   "source": [
    "###Training the entity recognizer\n",
    "\n",
    "\n",
    "#The entity recognizer tags words and phrases in context\n",
    "#Each token can only be part of one entity\n",
    "#Examples need to come with context\n",
    "\n",
    "doc = nlp(\"iPhone X is coming\")\n",
    "doc.ents = [Span(doc, 0, 2, label=\"GADGET\")]\n",
    "\n",
    "#Texts with no entities are also important\n",
    "\n",
    "doc = nlp(\"I need a new phone! Any tips?\")\n",
    "doc.ents = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The training data\n",
    "\n",
    "Examples of what we want the model to predict in context\n",
    "\n",
    "Update an existing model: a few hundred to a few thousand examples\n",
    "\n",
    "Train a new category: a few thousand to a million examples\n",
    "\n",
    "- spaCy's English models: 2 million words\n",
    "\n",
    "\n",
    "Usually created manually by human annotators\n",
    "\n",
    "Can be semi-automated – for example, using spaCy's Matcher!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training vs. evaluation data\n",
    "\n",
    "Training data: used to update the model\n",
    "\n",
    "\n",
    "Evaluation data:\n",
    "\n",
    "- data the model hasn't seen during training\n",
    "- used to calculate how accurate the model is\n",
    "- should be representative of the data the model will see at runtime\n",
    "\n",
    "\n",
    "When training your model, it's important to know how it's doing and whether it's learning the right thing. This is done by comparing the model's predictions on examples it hasn't seen during training to answers we already know. So in addition to the training data, you also need evaluation data, also called development data.\n",
    "\n",
    "The evaluation data is used to calculate how accurate your model is. For example, an accuracy score of 90% means that the model predicted 90% of the evaluation examples correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.blank(\"en\")\n",
    "\n",
    "# Create a Doc with entity spans\n",
    "doc1 = nlp(\"iPhone X is coming\")\n",
    "doc1.ents = [Span(doc1, 0, 2, label=\"GADGET\")]\n",
    "# Create another doc without entity spans\n",
    "doc2 = nlp(\"I need a new phone! Any tips?\")\n",
    "\n",
    "docs = [doc1, doc2]  # and so on..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'random' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Test folder\\KnowingSpacy\\training a nn\\training.ipynb Cell 8'\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Test%20folder/KnowingSpacy/training%20a%20nn/training.ipynb#ch0000012?line=0'>1</a>\u001b[0m \u001b[39m### Generating a training corpus (2)\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Test%20folder/KnowingSpacy/training%20a%20nn/training.ipynb#ch0000012?line=1'>2</a>\u001b[0m \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Test%20folder/KnowingSpacy/training%20a%20nn/training.ipynb#ch0000012?line=2'>3</a>\u001b[0m \u001b[39m#split data into two portions:\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Test%20folder/KnowingSpacy/training%20a%20nn/training.ipynb#ch0000012?line=3'>4</a>\u001b[0m \u001b[39m##- training data: used to update the model\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Test%20folder/KnowingSpacy/training%20a%20nn/training.ipynb#ch0000012?line=4'>5</a>\u001b[0m \u001b[39m##- development data: used to evaluate the model\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Test%20folder/KnowingSpacy/training%20a%20nn/training.ipynb#ch0000012?line=5'>6</a>\u001b[0m random\u001b[39m.\u001b[39mshuffle(docs)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Test%20folder/KnowingSpacy/training%20a%20nn/training.ipynb#ch0000012?line=6'>7</a>\u001b[0m train_docs \u001b[39m=\u001b[39m docs[:\u001b[39mlen\u001b[39m(docs) \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m \u001b[39m2\u001b[39m]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Test%20folder/KnowingSpacy/training%20a%20nn/training.ipynb#ch0000012?line=7'>8</a>\u001b[0m dev_docs \u001b[39m=\u001b[39m docs[\u001b[39mlen\u001b[39m(docs) \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m \u001b[39m2\u001b[39m:]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'random' is not defined"
     ]
    }
   ],
   "source": [
    "### Generating a training corpus (2)\n",
    "\n",
    "#split data into two portions:\n",
    "##- training data: used to update the model\n",
    "##- development data: used to evaluate the model\n",
    "random.shuffle(docs)\n",
    "train_docs = docs[:len(docs) // 2]\n",
    "dev_docs = docs[len(docs) // 2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DocBin: container to efficiently store and save Doc objects\n",
    "#can be saved to a binary file\n",
    "#binary files are used for training\n",
    "\n",
    "# Create and save a collection of training docs\n",
    "train_docbin = DocBin(docs=train_docs)\n",
    "train_docbin.to_disk(\"./train.spacy\")\n",
    "# Create and save a collection of evaluation docs\n",
    "dev_docbin = DocBin(docs=dev_docs)\n",
    "dev_docbin.to_disk(\"./dev.spacy\")\n",
    "\n",
    "\n",
    "### Converting your data\n",
    "# spacy convert lets you convert corpora in common formats\n",
    "# supports .conll, .conllu, .iob and spaCy's old JSON format\n",
    "$ python -m spacy convert ./train.gold.conll ./corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CREATING TRAINING DATA\n",
    "\n",
    "spaCy’s rule-based Matcher is a great way to quickly create training data for named entity models. A list of sentences is available as the variable TEXTS. You can print it to inspect it. We want to find all mentions of different iPhone models, so we can create training data to teach a model to recognize them as \"GADGET\".\n",
    "\n",
    "Write a pattern for two tokens whose lowercase forms match \"iphone\" and \"x\".\n",
    "\n",
    "Write a pattern for two tokens: one token whose lowercase form matches \"iphone\" and a digit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "from spacy.tokens import Span\n",
    "\n",
    "with open(\"exercises/en/iphone.json\", encoding=\"utf8\") as f:\n",
    "    TEXTS = json.loads(f.read())\n",
    "\n",
    "nlp = spacy.blank(\"en\")\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "# Two tokens whose lowercase forms match \"iphone\" and \"x\"\n",
    "pattern1 = [{\"LOWER\": \"iphone\"}, {\"LOWER\": \"x\"}]\n",
    "\n",
    "# Token whose lowercase form matches \"iphone\" and a digit\n",
    "pattern2 = [{\"LOWER\": \"iphone\"}, {\"IS_DIGIT\": True}]\n",
    "\n",
    "# Add patterns to the matcher and create docs with matched entities\n",
    "matcher.add(\"GADGET\", [pattern1, pattern2])\n",
    "docs = []\n",
    "for doc in nlp.pipe(TEXTS):\n",
    "    matches = matcher(doc)\n",
    "    spans = [Span(doc, start, end, label=match_id) for match_id, start, end in matches]\n",
    "    print(spans)\n",
    "    doc.ents = spans\n",
    "    docs.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After creating the data for our corpus, we need to save it out to a .spacy file. The code from the previous example is already available.\n",
    "\n",
    "# Instantiate the DocBin with the list of docs.\n",
    "# Save the DocBin to a file called train.spacy.\n",
    "\n",
    "import json\n",
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "from spacy.tokens import Span, DocBin\n",
    "\n",
    "with open(\"exercises/en/iphone.json\", encoding=\"utf8\") as f:\n",
    "    TEXTS = json.loads(f.read())\n",
    "\n",
    "nlp = spacy.blank(\"en\")\n",
    "matcher = Matcher(nlp.vocab)\n",
    "# Add patterns to the matcher\n",
    "pattern1 = ([{\"LOWER\": \"iphone\"}, {\"LOWER\": \"x\"}])\n",
    "pattern2 = [{\"LOWER\": \"iphone\"}, {\"IS_DIGIT\": True}]\n",
    "matcher.add(\"GADGET\", [pattern1, pattern2])\n",
    "docs = []\n",
    "for doc in nlp.pipe(TEXTS):\n",
    "    matches = matcher(doc)\n",
    "    spans = [Span(doc, start, end, label=match_id) for match_id, start, end in matches]\n",
    "    doc.ents = spans\n",
    "    docs.append(doc)\n",
    "\n",
    "doc_bin = DocBin(docs=docs)\n",
    "doc_bin.to_disk(\"./train.spacy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuring and running the training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "spaCy uses a config file, usually called config.cfg, as the \"single source of truth\" for all settings. The config file defines how to initialize the nlp object, which pipeline components to add and how their internal model implementations should be configured. It also includes all settings for the training process and how to load the data, including hyperparameters.\n",
    "\n",
    "Instead of providing lots of arguments on the command line or having to remember to define every single setting in code, you only need to pass your config file to spaCy's training command.\n",
    "\n",
    "Config files also help with reproducibility: you'll have all settings in one place and always know how your pipeline was trained. You can even check your config file into a Git repo to version it and share it with others so they can train the same pipeline with the same settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### The training config (2)\n",
    "[nlp]\n",
    "lang = \"en\"\n",
    "pipeline = [\"tok2vec\", \"ner\"]\n",
    "batch_size = 1000\n",
    "\n",
    "[nlp.tokenizer]\n",
    "@tokenizers = \"spacy.Tokenizer.v1\"\n",
    "\n",
    "[components]\n",
    "\n",
    "[components.ner]\n",
    "factory = \"ner\"\n",
    "\n",
    "[components.ner.model]\n",
    "@architectures = \"spacy.TransitionBasedParser.v2\"\n",
    "hidden_width = 64\n",
    "# And so on..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating a config\n",
    "\n",
    "\n",
    "spaCy can auto-generate a default config file for you\n",
    "interactive quickstart widget in the docs\n",
    "init config command on the CLI\n",
    "\n",
    "\n",
    "\n",
    "$ python -m spacy init config ./config.cfg --lang en --pipeline ner\n",
    "\n",
    "\n",
    "init config: the command to run\n",
    "\n",
    "config.cfg: output path for the generated config\n",
    "\n",
    "--lang: language class of the pipeline, e.g. en for English\n",
    "\n",
    "--pipeline: comma-separated names of components to include\n",
    "\n",
    "\n",
    "Alternatively, you can also use spaCy's built-in init config command. It takes the output file as the first argument. We usually call this file config.cfg. The argument --lang defines the language class that should be used for the pipeline, for example, en for English. The --pipeline argument lets you specify one or more comma-separated pipeline components to include. In this example, we're creating a config with one pipeline component, the named entity recognizer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training a pipeline (1)\n",
    "\n",
    "all you need is the config.cfg and the training and development data\n",
    "config settings can be overwritten on the command line\n",
    "\n",
    "$ python -m spacy train ./config.cfg --output ./output --paths.train train.spacy --paths.dev dev.spacy\n",
    "\n",
    "train: the command to run\n",
    "\n",
    "config.cfg: the path to the config file\n",
    "\n",
    "--output: the path to the output directory to save the trained pipeline\n",
    "\n",
    "--paths.train: override with path to the training data\n",
    "\n",
    "--paths.dev: override with path to the evaluation data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each pass over the data is also called an \"epoch\". This is shown in the first column of the table.\n",
    "\n",
    "Within each epoch, spaCy outputs the accuracy scores every 200 examples. These are the steps shown in the second column. You can change the frequency in the config. Each line shows the loss and calculated accuracy score at this point during training.\n",
    "\n",
    "The most interesting score to keep an eye on is the combined score in the last column. It reflects how accurately your model predicted the correct answers in the evaluation data.\n",
    "\n",
    "The training runs until the model stops improving and exits automatically."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading a trained pipeline\n",
    "\n",
    "\n",
    "output after training is a regular loadable spaCy pipeline\n",
    "- model-last: last trained pipeline\n",
    "- model-best: best trained pipeline\n",
    "\n",
    "The pipeline saved after training is a regular loadable spaCy pipeline – just like the trained pipelines provided by spaCy, for example en_core_web_sm. At the end, the last trained pipeline and the pipeline with the best score is saved to the output directory.\n",
    "\n",
    "\n",
    "load it with spacy.load\n",
    "\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"/path/to/output/model-best\")\n",
    "doc = nlp(\"iPhone 11 vs iPhone 8: What's the difference?\")\n",
    "print(doc.ents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Packaging your pipeline\n",
    "\n",
    "spacy package: create an installable Python package containing your pipeline\n",
    "easy to version and deploy\n",
    "\n",
    "$ python -m spacy package /path/to/output/model-best ./packages --name my_pipeline --version 1.0.0\n",
    "$ cd ./packages/en_my_pipeline-1.0.0\n",
    "$ pip install dist/en_my_pipeline-1.0.0.tar.gz\n",
    "\n",
    "\n",
    "Load and use the pipeline after installation:\n",
    "\n",
    "nlp = spacy.load(\"en_my_pipeline\")\n",
    "\n",
    "\n",
    "\n",
    "To make it easy to deploy your pipelines, spaCy provides a handy command to package them as Python packages. The spacy package command takes the path to your exported pipeline and an output directory. It then generates a Python package containing your pipeline. The Python package is a .tar.gz file and can be installed into your environment.\n",
    "\n",
    "You can also provide an optional name and version on the command. This lets you manage multiple different versions of a pipeline, for example, if you decide to customize your pipeline later or train it with more data.\n",
    "\n",
    "The package behaves just like any other Python package. After installation, you can load your pipeline using its name. Note that spaCy will automatically add the language code to the name. So your pipeline my_pipeline will become en_my_pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "The config.cfg file is the “single source of truth” for training a pipeline with spaCy. Which of the following is not true about the config?\n",
    "\n",
    "It allows you to configure the training process and hyperparameters.\n",
    "\n",
    "It helps make your training more reproducible.\n",
    "\n",
    "It creates an installable Python package with your pipeline. (correct)\n",
    "\n",
    "It defines the pipeline's components and their settings.\n",
    "\n",
    "Submit\n",
    "That's correct! The config file includes all settings related to training and how to set up the pipeline, but it doesn’t package your pipeline. To create an installable Python package, you can use the spacy package command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use spaCy’s init config command to auto-generate a config for an English pipeline.\n",
    "# Save the config to a file config.cfg.\n",
    "# Use the --pipeline argument to specify one pipeline component, ner.\n",
    "\n",
    "!python -m spacy init config ./config.cfg --lang en --pipeline ner\n",
    "\n",
    "\n",
    "!cat ./config.cfg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s use the config file generated in the previous exercise and the training corpus we’ve created to train a named entity recognizer!\n",
    "\n",
    "The train command lets you train a model from a training config file. A file config_gadget.cfg is already available in the directory exercises/en, as well as a file train_gadget.spacy containing the training examples, and a file dev_gadget.spacy containing the evaluation examples. Because we’re executing the command in a Jupyter environment in this course, we’re using the prefix !. If you’re running the command in your local terminal, you can leave this out.\n",
    "\n",
    "Call the train command with the file exercises/en/config_gadget.cfg.\n",
    "Save the trained pipeline to a directory output.\n",
    "Pass in the exercises/en/train_gadget.spacy and exercises/en/dev_gadget.spacy paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m spacy train ./exercises/en/config_gadget.cfg --output ./output --paths.train ./exercises/en/train_gadget.spacy --paths.dev ./exercises/en/dev_gadget.spacy"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "610efb86e122df48aab22117e29509e00a585e4642c6384735721f42f83ab1a2"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('projeto_apspacy')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
