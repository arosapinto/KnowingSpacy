{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PORTUGUESE TWEETS ANALYSIS - training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "from spacy.matcher import Matcher\n",
    "#spacy.cli.download(\"pt_core_news_lg\")\n",
    "from spacy import displacy\n",
    "from sklearn.model_selection import train_test_split\n",
    "from spacy.tokens import DocBin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"C:\\\\Test folder\\\\NoThemeTweets.csv\") as csv_file:\n",
    "    data = pd.read_csv(csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>tweet_date</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>query_used</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1031761728445530112</td>\n",
       "      <td>@Tixaa23 14 para eu ir :)</td>\n",
       "      <td>Tue Aug 21 04:35:39 +0000 2018</td>\n",
       "      <td>Positivo</td>\n",
       "      <td>:)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1031761040462278656</td>\n",
       "      <td>@drexalvarez O meu like eu já dei na época :)</td>\n",
       "      <td>Tue Aug 21 04:32:55 +0000 2018</td>\n",
       "      <td>Positivo</td>\n",
       "      <td>:)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1031760962372689920</td>\n",
       "      <td>Eu só queria conseguir comer alguma coisa pra ...</td>\n",
       "      <td>Tue Aug 21 04:32:37 +0000 2018</td>\n",
       "      <td>Positivo</td>\n",
       "      <td>:)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1031760948250456066</td>\n",
       "      <td>:D que lindo dia !</td>\n",
       "      <td>Tue Aug 21 04:32:33 +0000 2018</td>\n",
       "      <td>Positivo</td>\n",
       "      <td>:)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1031760895985246208</td>\n",
       "      <td>@Primo_Resmungao Pq da pr jeito!!é uma \"oferta...</td>\n",
       "      <td>Tue Aug 21 04:32:21 +0000 2018</td>\n",
       "      <td>Positivo</td>\n",
       "      <td>:)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id                                         tweet_text  \\\n",
       "0  1031761728445530112                          @Tixaa23 14 para eu ir :)   \n",
       "1  1031761040462278656      @drexalvarez O meu like eu já dei na época :)   \n",
       "2  1031760962372689920  Eu só queria conseguir comer alguma coisa pra ...   \n",
       "3  1031760948250456066                                 :D que lindo dia !   \n",
       "4  1031760895985246208  @Primo_Resmungao Pq da pr jeito!!é uma \"oferta...   \n",
       "\n",
       "                       tweet_date sentiment query_used  \n",
       "0  Tue Aug 21 04:35:39 +0000 2018  Positivo         :)  \n",
       "1  Tue Aug 21 04:32:55 +0000 2018  Positivo         :)  \n",
       "2  Tue Aug 21 04:32:37 +0000 2018  Positivo         :)  \n",
       "3  Tue Aug 21 04:32:33 +0000 2018  Positivo         :)  \n",
       "4  Tue Aug 21 04:32:21 +0000 2018  Positivo         :)  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[['tweet_text','sentiment']].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "Negativo    522707\n",
       "Positivo    263107\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby('sentiment').size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA PREPARATION for SPACY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train dataset: sentiment\n",
      "Negativo    1096\n",
      "Positivo    3904\n",
      "dtype: int64\n",
      "valid dataset: sentiment\n",
      "Negativo    4447\n",
      "Positivo     553\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Creating a train dataset and a validation dataset\n",
    "train_df = data[:90000].sample(n = 5000)\n",
    "print(\"train dataset:\", train_df.groupby('sentiment').size())\n",
    "\n",
    "valid_df = data[90001:200000].sample(n = 5000)\n",
    "print(\"valid dataset:\",valid_df.groupby('sentiment').size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "# Converting the dataframe into a list of tuples\n",
    "train_df['tuples'] = train_df.apply(lambda row: (row['tweet_text'],row['sentiment']), axis=1)\n",
    "train_data = train_df['tuples'].tolist()\n",
    "#train[:10]\n",
    "#print(train_data[0])\n",
    "print(type(train_data))\n",
    "\n",
    "valid_df['tuples'] = valid_df.apply(lambda row: (row['tweet_text'],row['sentiment']), axis=1)\n",
    "valid_data = valid_df['tuples'].tolist()\n",
    "#train[:10]\n",
    "#print(valid_data[0])\n",
    "print(type(valid_data))\n",
    "#print(valid_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"pt_core_news_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_docs(data):\n",
    "    docs = []\n",
    "    for doc, label in nlp.pipe(data, as_tuples=True):\n",
    "        if label == 'Negativo':\n",
    "            doc.cats[\"positive\"] = 0 #Maps a label to a score for categories applied to the document. \n",
    "            doc.cats[\"negative\"] = 1\n",
    "        else:\n",
    "            doc.cats[\"positive\"] = 1\n",
    "            doc.cats[\"negative\"] = 0\n",
    "        docs.append(doc)\n",
    "    return (docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create training and validation data\n",
    "num_texts = 800 # amount of validation and training generated\n",
    "\n",
    "train_docs = make_docs(train_data[:num_texts])\n",
    "doc_bin = DocBin(docs=train_docs)\n",
    "doc_bin.to_disk(\"./C:/Test folder/KnowingSpacy/self learning/trainpt.spacy\")\n",
    "\n",
    "valid_docs = make_docs(valid_data[:num_texts])\n",
    "doc_bin= DocBin(docs=valid_docs)\n",
    "doc_bin.to_disk(\"./C:/Test folder/KnowingSpacy/self learning/validpt.spacy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### To train the model\n",
    "\n",
    "# 1. create a base_config_model and copy data from  https://spacy.io/usage/training#quickstart\n",
    "# 2. update base_config.cfg file with the train and dev paths\n",
    "\n",
    "# anaconda prompt\n",
    "# 3.python -m spacy init fill-config ./base_config.cfg ./config.cfg\n",
    "# 4. open config\n",
    "# 3. python -m spacy train config.cfg --output ./output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Loss:\tThe training loss representing the amount of work left for the optimizer. Should decrease, but usually not to 0.\n",
    "\n",
    "- Precision (P):\tPercentage of predicted annotations that were correct. Should increase.\n",
    "\n",
    "- Recall (R):\tPercentage of reference annotations recovered. Should increase.\n",
    "\n",
    "- F-Score (F):\tHarmonic mean of precision and recall. Should increase.\n",
    "\n",
    "- UAS / LAS:\tUnlabeled and labeled attachment score for the dependency parser, i.e. the percentage of correct arcs. Should increase.\n",
    "\n",
    "- Speed:\tPrediction speed in words per second (WPS). Should stay stable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "610efb86e122df48aab22117e29509e00a585e4642c6384735721f42f83ab1a2"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('projeto_apspacy')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
