{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import random\n",
    "# from spacy import util\n",
    "from spacy.tokens import Doc\n",
    "from spacy.training import Example\n",
    "# from spacy.language import Language\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = [\n",
    "    (\"Type II diabetes are the most common ones.\", [(8,16, \"DISEASE\")]),\n",
    "    (\"In type 2 diabetes, there are primarily two interrelated problems at work.\", [(10,18, \"DISEASE\")]),\n",
    "    (\"You can lower your cholesterol by eating healthily and getting more exercise.\", [(19,30, \"DISEASE\")]),\n",
    "    (\"Treatment for this anemia can include blood transfusions to boost levels of red blood cells.\", [(19,25, \"DISEASE\")]),\n",
    "    (\"When Sebastian Thrun started working on self-driving cars at\", [(5,20, \"PERSON\")]), \n",
    "    (\"Google in 2007, few people outside of the company took him\", [(0, 6, 'ORG'), (10, 13, 'DATE')])\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load an existent spacy model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp = spacy.load('en_core_web_md')\n",
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('CARDINAL', 'DATE', 'EVENT', 'FAC', 'GPE', 'LANGUAGE', 'LAW', 'LOC', 'MONEY', 'NORP', 'ORDINAL', 'ORG', 'PERCENT', 'PERSON', 'PRODUCT', 'QUANTITY', 'TIME', 'WORK_OF_ART')\n"
     ]
    }
   ],
   "source": [
    "# Check the entities that are recognized by the ner model\n",
    "ori_ents = nlp.get_pipe('ner').labels\n",
    "print(ori_ents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select ner pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Existing Entities] =  ('CARDINAL', 'DATE', 'EVENT', 'FAC', 'GPE', 'LANGUAGE', 'LAW', 'LOC', 'MONEY', 'NORP', 'ORDINAL', 'ORG', 'PERCENT', 'PERSON', 'PRODUCT', 'QUANTITY', 'TIME', 'WORK_OF_ART')\n",
      "\n",
      "[All Entities] =  ('CARDINAL', 'DATE', 'DISEASE', 'EVENT', 'FAC', 'GPE', 'LANGUAGE', 'LAW', 'LOC', 'MONEY', 'NORP', 'ORDINAL', 'ORG', 'PERCENT', 'PERSON', 'PRODUCT', 'QUANTITY', 'TIME', 'WORK_OF_ART')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Pipelines in core pretrained model are tagger, parser, ner. Create new if blank model is to be trained using `spacy.blank('en')` else get the existing one.\n",
    "if \"ner\" not in nlp.pipe_names:\n",
    "    ner = nlp.create_pipe(\"ner\") # Creating the pipeline component\n",
    "    nlp.add_pipe(ner)\n",
    "else:\n",
    "    ner = nlp.get_pipe(\"ner\") # Getting the pipeline component\n",
    "\n",
    "### Add the new entity\n",
    "add_ents = ['DISEASE'] # The new entity\n",
    "ori_ents = nlp.get_pipe('ner').labels # All the existing entities recognised by the model\n",
    "print('[Existing Entities] = ', nlp.get_pipe('ner').labels)\n",
    "for ent in add_ents:\n",
    "    ner.add_label(ent)\n",
    "new_ents = nlp.get_pipe('ner').labels\n",
    "print('\\n[All Entities] = ', nlp.get_pipe('ner').labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Starting the Training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\APinto\\anaconda3\\envs\\projeto_apspacy\\lib\\site-packages\\spacy\\training\\iob_utils.py:141: UserWarning: [W030] Some entities could not be aligned in the text \"Google in 2007, few people outside of the company ...\" with entities \"[(0, 6, 'ORG'), (10, 13, 'DATE')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# DISABLE THE OTHER PIPES THAT DONT NEED TO CHANGE\n",
    "disabled_pipes = []\n",
    "for pipe_name in nlp.pipe_names:\n",
    "    if pipe_name != 'ner':\n",
    "        nlp.disable_pipes(pipe_name)\n",
    "        disabled_pipes.append(pipe_name)\n",
    "\n",
    "# train ner\n",
    "print(\"  Starting the Training ...\")\n",
    "optimizer = nlp.create_optimizer()\n",
    "for _ in range(25):\n",
    "    random.shuffle(train_data)\n",
    "    for raw_text, entity_offsets in train_data:\n",
    "        doc = nlp.make_doc(raw_text)\n",
    "        example = Example.from_dict(doc, {\"entities\": entity_offsets})\n",
    "        nlp.update([example], sgd=optimizer)\n",
    "\n",
    "\n",
    "# Enable all previously disabled pipe components\n",
    "for pipe_name in disabled_pipes:\n",
    "    nlp.enable_pipe(pipe_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "### function to print the entities\n",
    "def print_doc_entities(_doc: Doc):\n",
    "    if _doc.ents:\n",
    "        for _ent in _doc.ents:\n",
    "            print(f\"     {_ent.text} {_ent.label_}\")\n",
    "    else:\n",
    "        print(\"     NONE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict on new texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result AFTER training for cholesterol:\n",
      "     cholesterol DISEASE\n",
      "Result AFTER training  for diabetes:\n",
      "     diabetes DISEASE\n",
      "     diabetes DISEASE\n",
      "Result AFTER training  for DATE:\n",
      "     Google ORG\n",
      "     2007 DATE\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Result after training for cholesterol\n",
    "print(f\"Result AFTER training for cholesterol:\")\n",
    "doc = nlp(u'cholesterol')\n",
    "print_doc_entities(doc)\n",
    "\n",
    "# Result after training for diabetes\n",
    "print(f\"Result AFTER training  for diabetes:\")\n",
    "doc = nlp(u'The main difference between the two types of diabetes is that type 1 diabetes is a genetic disorder that often shows up early in life, and type 2 is largely diet-related and develops over time. ')\n",
    "print_doc_entities(doc)\n",
    "\n",
    "# Result after training for DATE\n",
    "print(f\"Result AFTER training  for DATE:\")\n",
    "doc = nlp(u'Google in 2007')\n",
    "print_doc_entities(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to \\content\n"
     ]
    }
   ],
   "source": [
    "### Save the model\n",
    "# Save the  model to directory\n",
    "\n",
    "output_dir = Path('/content/')\n",
    "nlp.to_disk(output_dir)\n",
    "print(\"Saved model to\", output_dir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload the saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from \\content\n",
      "Entities [('anemia', 'DISEASE')]\n"
     ]
    }
   ],
   "source": [
    "# Load the saved model and predict\n",
    "print(\"Loading from\", output_dir)\n",
    "nlp_updated = spacy.load(output_dir)\n",
    "doc = nlp_updated(\"Several signs and symptoms occur in all types of anemia, such as fatigue, shortness of breath and feeling cold.\" )\n",
    "print(\"Entities\", [(ent.text, ent.label_) for ent in doc.ents])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entities [('cholesterol', 'DISEASE'), ('Coronavirus', 'ORG'), ('2019', 'DISEASE'), ('COVID-19', 'ORG'), ('2020', 'DATE')]\n"
     ]
    }
   ],
   "source": [
    "doc = nlp_updated(\"The fiber and potassium in bananas can help lower cholesterol and blood pressure. Coronavirus disease 2019 (COVID-19) dominated 2020. This is a look back at how the pandemic evolved and progressed through the year, which closed with the arrival of vaccines, but also continued challenges.\" )\n",
    "print(\"Entities\", [(ent.text, ent.label_) for ent in doc.ents])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']\n"
     ]
    }
   ],
   "source": [
    "print(nlp_updated.pipe_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('CARDINAL', 'DATE', 'DISEASE', 'EVENT', 'FAC', 'GPE', 'LANGUAGE', 'LAW', 'LOC', 'MONEY', 'NORP', 'ORDINAL', 'ORG', 'PERCENT', 'PERSON', 'PRODUCT', 'QUANTITY', 'TIME', 'WORK_OF_ART')\n"
     ]
    }
   ],
   "source": [
    "print(nlp_updated.get_pipe('ner').labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_updated = spacy.load(output_dir)\n",
    "from spacy.training import biluo_tags_to_spans\n",
    "from spacy.language import Language\n",
    "\n",
    "@Language.component(\"custom_ner_wrapper\")\n",
    "def custom_ner_wrapper(doc):\n",
    "    words = [token.text for token in doc]\n",
    "    custom_entities = nlp_updated(words)\n",
    "    doc.ents = biluo_tags_to_spans(doc, custom_entities)\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "[E866] Expected a string or 'Doc' as input, but got: <class 'list'>.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Test folder\\KnowingSpacy\\self learning\\Adding entity.ipynb Cell 21'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Test%20folder/KnowingSpacy/self%20learning/Adding%20entity.ipynb#ch0000018?line=0'>1</a>\u001b[0m a \u001b[39m=\u001b[39m custom_ner_wrapper(doc)\n",
      "\u001b[1;32mc:\\Test folder\\KnowingSpacy\\self learning\\Adding entity.ipynb Cell 20'\u001b[0m in \u001b[0;36mcustom_ner_wrapper\u001b[1;34m(doc)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Test%20folder/KnowingSpacy/self%20learning/Adding%20entity.ipynb#ch0000017?line=4'>5</a>\u001b[0m \u001b[39m@Language\u001b[39m\u001b[39m.\u001b[39mcomponent(\u001b[39m\"\u001b[39m\u001b[39mcustom_ner_wrapper\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Test%20folder/KnowingSpacy/self%20learning/Adding%20entity.ipynb#ch0000017?line=5'>6</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcustom_ner_wrapper\u001b[39m(doc):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Test%20folder/KnowingSpacy/self%20learning/Adding%20entity.ipynb#ch0000017?line=6'>7</a>\u001b[0m     words \u001b[39m=\u001b[39m [token\u001b[39m.\u001b[39mtext \u001b[39mfor\u001b[39;00m token \u001b[39min\u001b[39;00m doc]\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Test%20folder/KnowingSpacy/self%20learning/Adding%20entity.ipynb#ch0000017?line=7'>8</a>\u001b[0m     custom_entities \u001b[39m=\u001b[39m nlp_updated(words)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Test%20folder/KnowingSpacy/self%20learning/Adding%20entity.ipynb#ch0000017?line=8'>9</a>\u001b[0m     doc\u001b[39m.\u001b[39ments \u001b[39m=\u001b[39m biluo_tags_to_spans(doc, custom_entities)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Test%20folder/KnowingSpacy/self%20learning/Adding%20entity.ipynb#ch0000017?line=9'>10</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m doc\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\projeto_apspacy\\lib\\site-packages\\spacy\\language.py:1005\u001b[0m, in \u001b[0;36mLanguage.__call__\u001b[1;34m(self, text, disable, component_cfg)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/APinto/anaconda3/envs/projeto_apspacy/lib/site-packages/spacy/language.py?line=983'>984</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\n\u001b[0;32m    <a href='file:///c%3A/Users/APinto/anaconda3/envs/projeto_apspacy/lib/site-packages/spacy/language.py?line=984'>985</a>\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    <a href='file:///c%3A/Users/APinto/anaconda3/envs/projeto_apspacy/lib/site-packages/spacy/language.py?line=985'>986</a>\u001b[0m     text: Union[\u001b[39mstr\u001b[39m, Doc],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/APinto/anaconda3/envs/projeto_apspacy/lib/site-packages/spacy/language.py?line=988'>989</a>\u001b[0m     component_cfg: Optional[Dict[\u001b[39mstr\u001b[39m, Dict[\u001b[39mstr\u001b[39m, Any]]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    <a href='file:///c%3A/Users/APinto/anaconda3/envs/projeto_apspacy/lib/site-packages/spacy/language.py?line=989'>990</a>\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Doc:\n\u001b[0;32m    <a href='file:///c%3A/Users/APinto/anaconda3/envs/projeto_apspacy/lib/site-packages/spacy/language.py?line=990'>991</a>\u001b[0m     \u001b[39m\"\"\"Apply the pipeline to some text. The text can span multiple sentences,\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/APinto/anaconda3/envs/projeto_apspacy/lib/site-packages/spacy/language.py?line=991'>992</a>\u001b[0m \u001b[39m    and can contain arbitrary whitespace. Alignment into the original string\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/APinto/anaconda3/envs/projeto_apspacy/lib/site-packages/spacy/language.py?line=992'>993</a>\u001b[0m \u001b[39m    is preserved.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/APinto/anaconda3/envs/projeto_apspacy/lib/site-packages/spacy/language.py?line=1002'>1003</a>\u001b[0m \u001b[39m    DOCS: https://spacy.io/api/language#call\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/APinto/anaconda3/envs/projeto_apspacy/lib/site-packages/spacy/language.py?line=1003'>1004</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> <a href='file:///c%3A/Users/APinto/anaconda3/envs/projeto_apspacy/lib/site-packages/spacy/language.py?line=1004'>1005</a>\u001b[0m     doc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_ensure_doc(text)\n\u001b[0;32m   <a href='file:///c%3A/Users/APinto/anaconda3/envs/projeto_apspacy/lib/site-packages/spacy/language.py?line=1005'>1006</a>\u001b[0m     \u001b[39mif\u001b[39;00m component_cfg \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   <a href='file:///c%3A/Users/APinto/anaconda3/envs/projeto_apspacy/lib/site-packages/spacy/language.py?line=1006'>1007</a>\u001b[0m         component_cfg \u001b[39m=\u001b[39m {}\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\projeto_apspacy\\lib\\site-packages\\spacy\\language.py:1096\u001b[0m, in \u001b[0;36mLanguage._ensure_doc\u001b[1;34m(self, doc_like)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/APinto/anaconda3/envs/projeto_apspacy/lib/site-packages/spacy/language.py?line=1093'>1094</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(doc_like, \u001b[39mstr\u001b[39m):\n\u001b[0;32m   <a href='file:///c%3A/Users/APinto/anaconda3/envs/projeto_apspacy/lib/site-packages/spacy/language.py?line=1094'>1095</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmake_doc(doc_like)\n\u001b[1;32m-> <a href='file:///c%3A/Users/APinto/anaconda3/envs/projeto_apspacy/lib/site-packages/spacy/language.py?line=1095'>1096</a>\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(Errors\u001b[39m.\u001b[39mE866\u001b[39m.\u001b[39mformat(\u001b[39mtype\u001b[39m\u001b[39m=\u001b[39m\u001b[39mtype\u001b[39m(doc_like)))\n",
      "\u001b[1;31mValueError\u001b[0m: [E866] Expected a string or 'Doc' as input, but got: <class 'list'>."
     ]
    }
   ],
   "source": [
    "a = custom_ner_wrapper(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "610efb86e122df48aab22117e29509e00a585e4642c6384735721f42f83ab1a2"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('projeto_apspacy')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
