{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import random\n",
    "# from spacy import util\n",
    "from spacy.tokens import Doc\n",
    "from spacy.training import Example\n",
    "# from spacy.language import Language\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = [\n",
    "    (\"Type II diabetes are the most common ones.\", [(8,16, \"DISEASE\")]),\n",
    "    (\"In type 2 diabetes, there are primarily two interrelated problems at work.\", [(10,18, \"DISEASE\")]),\n",
    "    (\"You can lower your cholesterol by eating healthily and getting more exercise.\", [(19,30, \"DISEASE\")]),\n",
    "    (\"Treatment for this anemia can include blood transfusions to boost levels of red blood cells.\", [(19,25, \"DISEASE\")]),\n",
    "    (\"When Sebastian Thrun started working on self-driving cars at\", [(5,20, \"PERSON\")]), \n",
    "    (\"Google in 2007, few people outside of the company took him\", [(0, 6, 'ORG'), (10, 13, 'DATE')])\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load an existent spacy model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp = spacy.load('en_core_web_md')\n",
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('CARDINAL', 'DATE', 'EVENT', 'FAC', 'GPE', 'LANGUAGE', 'LAW', 'LOC', 'MONEY', 'NORP', 'ORDINAL', 'ORG', 'PERCENT', 'PERSON', 'PRODUCT', 'QUANTITY', 'TIME', 'WORK_OF_ART')\n"
     ]
    }
   ],
   "source": [
    "# Check the entities that are recognized by the ner model\n",
    "ori_ents = nlp.get_pipe('ner').labels\n",
    "print(ori_ents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select ner pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Existing Entities] =  ('CARDINAL', 'DATE', 'DISEASE', 'EVENT', 'FAC', 'GPE', 'LANGUAGE', 'LAW', 'LOC', 'MONEY', 'NORP', 'ORDINAL', 'ORG', 'PERCENT', 'PERSON', 'PRODUCT', 'QUANTITY', 'TIME', 'WORK_OF_ART')\n",
      "\n",
      "[All Entities] =  ('CARDINAL', 'DATE', 'DISEASE', 'EVENT', 'FAC', 'GPE', 'LANGUAGE', 'LAW', 'LOC', 'MONEY', 'NORP', 'ORDINAL', 'ORG', 'PERCENT', 'PERSON', 'PRODUCT', 'QUANTITY', 'TIME', 'WORK_OF_ART')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Pipelines in core pretrained model are tagger, parser, ner. Create new if blank model is to be trained using `spacy.blank('en')` else get the existing one.\n",
    "if \"ner\" not in nlp.pipe_names:\n",
    "    ner = nlp.create_pipe(\"ner\") # Creating the pipeline component\n",
    "    nlp.add_pipe(ner)\n",
    "else:\n",
    "    ner = nlp.get_pipe(\"ner\") # Getting the pipeline component\n",
    "\n",
    "### Add the new entity\n",
    "add_ents = ['DISEASE'] # The new entity\n",
    "ori_ents = nlp.get_pipe('ner').labels # All the existing entities recognised by the model\n",
    "print('[Existing Entities] = ', nlp.get_pipe('ner').labels)\n",
    "for ent in add_ents:\n",
    "    ner.add_label(ent)\n",
    "new_ents = nlp.get_pipe('ner').labels\n",
    "print('\\n[All Entities] = ', nlp.get_pipe('ner').labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\APinto\\anaconda3\\envs\\projeto_apspacy\\lib\\site-packages\\spacy\\training\\iob_utils.py:141: UserWarning: [W030] Some entities could not be aligned in the text \"Google in 2007, few people outside of the company ...\" with entities \"[(0, 6, 'ORG'), (10, 13, 'DATE')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# DISABLE THE OTHER PIPES THAT DONT NEED TO CHANGE\n",
    "disabled_pipes = []\n",
    "for pipe_name in nlp.pipe_names:\n",
    "    if pipe_name != 'ner':\n",
    "        nlp.disable_pipes(pipe_name)\n",
    "        disabled_pipes.append(pipe_name)\n",
    "\n",
    "# train ner\n",
    "print(\"  Starting the Training ...\")\n",
    "optimizer = nlp.create_optimizer()\n",
    "for _ in range(25):\n",
    "    random.shuffle(train_data)\n",
    "    for raw_text, entity_offsets in train_data:\n",
    "        doc = nlp.make_doc(raw_text)\n",
    "        example = Example.from_dict(doc, {\"entities\": entity_offsets})\n",
    "        nlp.update([example], sgd=optimizer)\n",
    "\n",
    "\n",
    "# Enable all previously disabled pipe components\n",
    "for pipe_name in disabled_pipes:\n",
    "    nlp.enable_pipe(pipe_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "### function to print the entities\n",
    "def print_doc_entities(_doc: Doc):\n",
    "    if _doc.ents:\n",
    "        for _ent in _doc.ents:\n",
    "            print(f\"     {_ent.text} {_ent.label_}\")\n",
    "    else:\n",
    "        print(\"     NONE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict on new texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result AFTER training for cholesterol:\n",
      "     cholesterol DISEASE\n",
      "Result AFTER training  for diabetes:\n",
      "     diabetes DISEASE\n",
      "     diabetes DISEASE\n",
      "Result AFTER training  for DATE:\n",
      "     Google ORG\n",
      "     2007 DATE\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Result after training for cholesterol\n",
    "print(f\"Result AFTER training for cholesterol:\")\n",
    "doc = nlp(u'cholesterol')\n",
    "print_doc_entities(doc)\n",
    "\n",
    "# Result after training for diabetes\n",
    "print(f\"Result AFTER training  for diabetes:\")\n",
    "doc = nlp(u'The main difference between the two types of diabetes is that type 1 diabetes is a genetic disorder that often shows up early in life, and type 2 is largely diet-related and develops over time. ')\n",
    "print_doc_entities(doc)\n",
    "\n",
    "# Result after training for DATE\n",
    "print(f\"Result AFTER training  for DATE:\")\n",
    "doc = nlp(u'Google in 2007')\n",
    "print_doc_entities(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to \\content\n"
     ]
    }
   ],
   "source": [
    "### Save the model\n",
    "# Save the  model to directory\n",
    "\n",
    "output_dir = Path('/content/')\n",
    "nlp.to_disk(output_dir)\n",
    "print(\"Saved model to\", output_dir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload the saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from \\content\n",
      "Entities [('anemia', 'DISEASE')]\n"
     ]
    }
   ],
   "source": [
    "# Load the saved model and predict\n",
    "print(\"Loading from\", output_dir)\n",
    "nlp_updated = spacy.load(output_dir)\n",
    "doc = nlp_updated(\"Several signs and symptoms occur in all types of anemia, such as fatigue, shortness of breath and feeling cold.\" )\n",
    "print(\"Entities\", [(ent.text, ent.label_) for ent in doc.ents])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entities [('cholesterol', 'DISEASE'), ('Coronavirus', 'ORG'), ('2019', 'DISEASE'), ('COVID-19', 'ORG'), ('2020', 'DATE')]\n"
     ]
    }
   ],
   "source": [
    "doc = nlp_updated(\"The fiber and potassium in bananas can help lower cholesterol and blood pressure. Coronavirus disease 2019 (COVID-19) dominated 2020. This is a look back at how the pandemic evolved and progressed through the year, which closed with the arrival of vaccines, but also continued challenges.\" )\n",
    "print(\"Entities\", [(ent.text, ent.label_) for ent in doc.ents])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "610efb86e122df48aab22117e29509e00a585e4642c6384735721f42f83ab1a2"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('projeto_apspacy')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
