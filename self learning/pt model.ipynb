{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SPACY PORTUGUESE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- STOP WORDS LIST:  https://github.com/explosion/spaCy/blob/master/spacy/lang/pt/stop_words.py\n",
    "\n",
    "- PUNCTUATION: https://github.com/explosion/spaCy/blob/master/spacy/lang/pt/punctuation.py\n",
    "\n",
    "- LANGUAGE DATA: https://spacy.io/usage/linguistic-features#language-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -U spacy\n",
    "# python -m spacy download pt_core_news_lg\n",
    "\n",
    "import spacy\n",
    "import pandas as pd\n",
    "#spacy.cli.download(\"pt_core_news_lg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"pt_core_news_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tok2vec', 'morphologizer', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']\n"
     ]
    }
   ],
   "source": [
    "print(nlp.pipe_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('LOC', 'MISC', 'ORG', 'PER')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ents = nlp.get_pipe('ner').labels\n",
    "ents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"O Real Mosteiro de Santa Maria de Bel√©m, designado comumente por Mosteiro dos Jer√≥nimos, por ter sido destinado √† Ordem de S√£o Jer√≥nimo, √© uma obra-prima da arquitetura portuguesa. Classificado Monumento Nacional, em 1907, e inscrito na Lista do Patrim√≥nio Mundial da UNESCO, em 1983, est√° vinculado ao Protocolo do Estado. A igreja, sede da Par√≥quia de Santa Maria de Bel√©m, com servi√ßo religioso e hor√°rio para vistas patrimoniais, e o claustro, secularizado no s√©culo XIX, t√™m acesso distinto e formam o conjunto patrimonial mais visitado do Pa√≠s.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Real Mosteiro de Santa Maria de Bel√©m LOC\n",
      "     Mosteiro dos Jer√≥nimos LOC\n",
      "     Ordem de S√£o Jer√≥nimo ORG\n",
      "     Monumento Nacional LOC\n",
      "     Lista do Patrim√≥nio Mundial da UNESCO MISC\n",
      "     Protocolo do Estado MISC\n",
      "     Par√≥quia de Santa Maria de Bel√©m LOC\n",
      "     Pa√≠s LOC\n",
      "Entity not available\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(text)\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print(f\"     {ent.text} {ent.label_}\")\n",
    "else:\n",
    "    print(\"Entity not available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>lemma</th>\n",
       "      <th>pos</th>\n",
       "      <th>tag</th>\n",
       "      <th>dep</th>\n",
       "      <th>shape</th>\n",
       "      <th>is_alpha</th>\n",
       "      <th>is_stop</th>\n",
       "      <th>is_punctuation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>O</td>\n",
       "      <td>(O,)</td>\n",
       "      <td>DET</td>\n",
       "      <td>DET</td>\n",
       "      <td>det</td>\n",
       "      <td>X</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Real</td>\n",
       "      <td>(Real,)</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>Xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mosteiro</td>\n",
       "      <td>(Mosteiro,)</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>flat:name</td>\n",
       "      <td>Xxxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>de</td>\n",
       "      <td>(de,)</td>\n",
       "      <td>ADP</td>\n",
       "      <td>ADP</td>\n",
       "      <td>case</td>\n",
       "      <td>xx</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Santa</td>\n",
       "      <td>(Santa,)</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>nmod</td>\n",
       "      <td>Xxxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>mais</td>\n",
       "      <td>(mais,)</td>\n",
       "      <td>ADV</td>\n",
       "      <td>ADV</td>\n",
       "      <td>advmod</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>visitado</td>\n",
       "      <td>(visitar,)</td>\n",
       "      <td>VERB</td>\n",
       "      <td>VERB</td>\n",
       "      <td>acl</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>do</td>\n",
       "      <td>(do,)</td>\n",
       "      <td>ADP</td>\n",
       "      <td>ADP</td>\n",
       "      <td>case</td>\n",
       "      <td>xx</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>Pa√≠s</td>\n",
       "      <td>(Pa√≠s,)</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>obl</td>\n",
       "      <td>Xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>.</td>\n",
       "      <td>(.,)</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>punct</td>\n",
       "      <td>.</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>103 rows √ó 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         text        lemma    pos    tag        dep  shape is_alpha is_stop  \\\n",
       "0           O         (O,)    DET    DET        det      X     True    True   \n",
       "1        Real      (Real,)  PROPN  PROPN      nsubj   Xxxx     True   False   \n",
       "2    Mosteiro  (Mosteiro,)  PROPN  PROPN  flat:name  Xxxxx     True   False   \n",
       "3          de        (de,)    ADP    ADP       case     xx     True    True   \n",
       "4       Santa     (Santa,)  PROPN  PROPN       nmod  Xxxxx     True   False   \n",
       "..        ...          ...    ...    ...        ...    ...      ...     ...   \n",
       "98       mais      (mais,)    ADV    ADV     advmod   xxxx     True    True   \n",
       "99   visitado   (visitar,)   VERB   VERB        acl   xxxx     True   False   \n",
       "100        do        (do,)    ADP    ADP       case     xx     True    True   \n",
       "101      Pa√≠s      (Pa√≠s,)  PROPN  PROPN        obl   Xxxx     True   False   \n",
       "102         .         (.,)  PUNCT  PUNCT      punct      .    False   False   \n",
       "\n",
       "    is_punctuation  \n",
       "0            False  \n",
       "1            False  \n",
       "2            False  \n",
       "3            False  \n",
       "4            False  \n",
       "..             ...  \n",
       "98           False  \n",
       "99           False  \n",
       "100          False  \n",
       "101          False  \n",
       "102           True  \n",
       "\n",
       "[103 rows x 9 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for token in doc:\n",
    "#     print(token.text, token.lemma_, token.pos_, token.tag_, token.dep_,\n",
    "#             token.shape_, token.is_alpha, token.is_stop)\n",
    "\n",
    "\n",
    "tokenized_text = pd.DataFrame()\n",
    "\n",
    "for i, token in enumerate(doc):\n",
    "    tokenized_text.loc[i, 'text'] = token.text\n",
    "    tokenized_text.loc[i, 'lemma'] = token.lemma_,\n",
    "    tokenized_text.loc[i, 'pos'] = token.pos_\n",
    "    tokenized_text.loc[i, 'tag'] = token.tag_\n",
    "    tokenized_text.loc[i, 'dep'] = token.dep_\n",
    "    tokenized_text.loc[i, 'shape'] = token.shape_\n",
    "    tokenized_text.loc[i, 'is_alpha'] = token.is_alpha\n",
    "    tokenized_text.loc[i, 'is_stop'] = token.is_stop\n",
    "    tokenized_text.loc[i, 'is_punctuation'] = token.is_punct\n",
    "\n",
    "tokenized_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PORTUGUESE TWEETS ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"C:\\\\Test folder\\\\NoThemeTweets.csv\") as csv_file:\n",
    "    data = pd.read_csv(csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>tweet_date</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>query_used</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1031761728445530112</td>\n",
       "      <td>@Tixaa23 14 para eu ir :)</td>\n",
       "      <td>Tue Aug 21 04:35:39 +0000 2018</td>\n",
       "      <td>Positivo</td>\n",
       "      <td>:)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1031761040462278656</td>\n",
       "      <td>@drexalvarez O meu like eu j√° dei na √©poca :)</td>\n",
       "      <td>Tue Aug 21 04:32:55 +0000 2018</td>\n",
       "      <td>Positivo</td>\n",
       "      <td>:)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1031760962372689920</td>\n",
       "      <td>Eu s√≥ queria conseguir comer alguma coisa pra ...</td>\n",
       "      <td>Tue Aug 21 04:32:37 +0000 2018</td>\n",
       "      <td>Positivo</td>\n",
       "      <td>:)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1031760948250456066</td>\n",
       "      <td>:D que lindo dia !</td>\n",
       "      <td>Tue Aug 21 04:32:33 +0000 2018</td>\n",
       "      <td>Positivo</td>\n",
       "      <td>:)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1031760895985246208</td>\n",
       "      <td>@Primo_Resmungao Pq da pr jeito!!√© uma \"oferta...</td>\n",
       "      <td>Tue Aug 21 04:32:21 +0000 2018</td>\n",
       "      <td>Positivo</td>\n",
       "      <td>:)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id                                         tweet_text  \\\n",
       "0  1031761728445530112                          @Tixaa23 14 para eu ir :)   \n",
       "1  1031761040462278656      @drexalvarez O meu like eu j√° dei na √©poca :)   \n",
       "2  1031760962372689920  Eu s√≥ queria conseguir comer alguma coisa pra ...   \n",
       "3  1031760948250456066                                 :D que lindo dia !   \n",
       "4  1031760895985246208  @Primo_Resmungao Pq da pr jeito!!√© uma \"oferta...   \n",
       "\n",
       "                       tweet_date sentiment query_used  \n",
       "0  Tue Aug 21 04:35:39 +0000 2018  Positivo         :)  \n",
       "1  Tue Aug 21 04:32:55 +0000 2018  Positivo         :)  \n",
       "2  Tue Aug 21 04:32:37 +0000 2018  Positivo         :)  \n",
       "3  Tue Aug 21 04:32:33 +0000 2018  Positivo         :)  \n",
       "4  Tue Aug 21 04:32:21 +0000 2018  Positivo         :)  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(785814, 5)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "()"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ents = nlp.get_pipe('attribute_ruler').\n",
    "ents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('ROOT',\n",
       " 'acl',\n",
       " 'acl:relcl',\n",
       " 'advcl',\n",
       " 'advmod',\n",
       " 'amod',\n",
       " 'appos',\n",
       " 'aux',\n",
       " 'aux:pass',\n",
       " 'case',\n",
       " 'cc',\n",
       " 'ccomp',\n",
       " 'compound',\n",
       " 'conj',\n",
       " 'cop',\n",
       " 'csubj',\n",
       " 'dep',\n",
       " 'det',\n",
       " 'discourse',\n",
       " 'expl',\n",
       " 'fixed',\n",
       " 'flat',\n",
       " 'flat:foreign',\n",
       " 'flat:name',\n",
       " 'iobj',\n",
       " 'mark',\n",
       " 'nmod',\n",
       " 'nsubj',\n",
       " 'nsubj:pass',\n",
       " 'nummod',\n",
       " 'obj',\n",
       " 'obl',\n",
       " 'obl:agent',\n",
       " 'parataxis',\n",
       " 'punct',\n",
       " 'xcomp')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ents = nlp.get_pipe('parser').labels\n",
    "ents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "()"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ents = nlp.get_pipe('tok2vec').labels\n",
    "ents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                             @Tixaa23 14 para eu ir :)\n",
       "1         @drexalvarez O meu like eu j√° dei na √©poca :)\n",
       "2     Eu s√≥ queria conseguir comer alguma coisa pra ...\n",
       "3                                    :D que lindo dia !\n",
       "4     @Primo_Resmungao Pq da pr jeito!!√© uma \"oferta...\n",
       "                            ...                        \n",
       "95              @rihanney se voc√™ n√£o for me ignorar :)\n",
       "96    Comeu eshilley n√© safado OKAISUWOSOKSSKSISSJS ...\n",
       "97      @beamarcelino Aleat√≥rias n√£o, bora construir :)\n",
       "98                                  Mas fui ao mc :))))\n",
       "99    vi sua namorada sem voce no role vcs terminara...\n",
       "Name: tweet_text, Length: 100, dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = data['tweet_text'][:100]\n",
    "tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = []\n",
    "type(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['@Tixaa23 14 para eu ir :)', '@drexalvarez O meu like eu j√° dei na √©poca :)', 'Eu s√≥ queria conseguir comer alguma coisa pra poder dormir :)', ':D que lindo dia !', '@Primo_Resmungao Pq da pr jeito!!√© uma \"oferta\", ha q aproveitar. :P', '@BadWolf_Wagner @DanieVedo Eu entendi, mas isso foi mais porque eu pensei em outra coisa. :P', '@Chyko661 @g1 [+] Carcinoma Hepatico (Cancer de Figado). Deivison lutou contra a doen√ßa por um ano e faleceu ontem a tarde. Espero que minha explica√ßao tenha te ajudado. :)', 'Aquela mina da limpeza, que tinha um marido com meu problema me adicionou aqui no face, esquisito a princ√≠pio mas ah, nega velha e pa, veio perguntar como eu t√¥ :) Ela deve ter tomado as dor, me viu malzao e p√°.', '@narryfools aqui, espero que voc√™ melhore logo :) https://t.co/OBiMIrbU9F', '@fefocaires se √©s feliz trabalhando nisso ent√£o n√£o pare se as pessoas se incomodam com sua opini√£o √© pq elas te d√£o ouvido e seu trabalho tem um grande alcance :)', 'vamos se seguir no insta? se quiser sdv :) #TercaDetremuraSDV', '@youngsnowblood @thegr8angelica a para vc q √© ‚ô•Ô∏è‚ô•Ô∏è mt obg, eu me sinto at√© melhor agr :)', 'foo :) : 400e84d5-1e93-4d95-8280-2d99fc5bbb12', \"Quando voc√™ joga com um youtuber que voc√™ segue e nem percebe na hora rs. Hope I've beaten you mr. @Alex_Olney from @nintendolife :P https://t.co/FMnZCneQUa\", '@bebadoetriste √© pra fazer torresmo :)', '@Calebe80781696 Vixe q treta novelesca! Que bom a amizade foi forte e vcs est√£o conectados ainda! :)))', 'Aqui lembrando o shade das donzelas. :) A Camila foi perguntanda em uma entrevista e disse que na hora estava em casa e AT√â chorou vendo isso. https://t.co/HDIPdpaTgM', '@LelloucheNico Bravo ! :)', 'Gostei de um v√≠deo @YouTube https://t.co/FGEgHwa67q(üî¥LIVE) FORTNITE DA NIGHT :D - LEOZERA - PC', 'Nenhum dos itens s√£o meus. T√¥ s√≥ fazendo aquela divulga√ß√£o :D SP tem prefer√™ncia pra entrega em m√£os, mas a gente faz uns Sedex a√≠ e tal RT do amor pra chegar no pr√≥ximo Faker!']\n"
     ]
    }
   ],
   "source": [
    "tweets = []\n",
    "for i in data['tweet_text'][:20]:\n",
    "    #print('working',  i)\n",
    "    tweets.append(i)\n",
    "print(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PER --> Carcinoma Hepatico\n",
      "PER --> Deivison\n",
      "PER --> @fefocaires\n",
      "PER --> A Camila\n",
      "PER --> AT√â\n"
     ]
    }
   ],
   "source": [
    "# Merge noun phrases and entities for easier analysis\n",
    "# nlp.add_pipe(\"merge_entities\")\n",
    "# nlp.add_pipe(\"merge_noun_chunks\")\n",
    "\n",
    "for doc in nlp.pipe(tweets):\n",
    "    for token in doc:\n",
    "        if token.ent_type_ == \"PER\" or token.ent_type_ == \"ORG\":\n",
    "            print(token.ent_type_, \"-->\", token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in nlp.pipe(tweets):\n",
    "    for token in doc:\n",
    "        if token.ent_type_ in ents:\n",
    "            print(ents, \"-->\", token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "610efb86e122df48aab22117e29509e00a585e4642c6384735721f42f83ab1a2"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('projeto_apspacy')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
