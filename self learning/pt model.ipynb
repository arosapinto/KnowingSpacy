{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SPACY PORTUGUESE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- STOP WORDS LIST:  https://github.com/explosion/spaCy/blob/master/spacy/lang/pt/stop_words.py\n",
    "\n",
    "- PUNCTUATION: https://github.com/explosion/spaCy/blob/master/spacy/lang/pt/punctuation.py\n",
    "\n",
    "- LANGUAGE DATA: https://spacy.io/usage/linguistic-features#language-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -U spacy\n",
    "# python -m spacy download pt_core_news_lg\n",
    "\n",
    "import spacy\n",
    "import pandas as pd\n",
    "#spacy.cli.download(\"pt_core_news_lg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"pt_core_news_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tok2vec', 'morphologizer', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']\n"
     ]
    }
   ],
   "source": [
    "print(nlp.pipe_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('LOC', 'MISC', 'ORG', 'PER')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ents = nlp.get_pipe('ner').labels\n",
    "ents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"O Real Mosteiro de Santa Maria de Belém, designado comumente por Mosteiro dos Jerónimos, por ter sido destinado à Ordem de São Jerónimo, é uma obra-prima da arquitetura portuguesa. Classificado Monumento Nacional, em 1907, e inscrito na Lista do Património Mundial da UNESCO, em 1983, está vinculado ao Protocolo do Estado. A igreja, sede da Paróquia de Santa Maria de Belém, com serviço religioso e horário para vistas patrimoniais, e o claustro, secularizado no século XIX, têm acesso distinto e formam o conjunto patrimonial mais visitado do País.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Real Mosteiro de Santa Maria de Belém LOC\n",
      "     Mosteiro dos Jerónimos LOC\n",
      "     Ordem de São Jerónimo ORG\n",
      "     Monumento Nacional LOC\n",
      "     Lista do Património Mundial da UNESCO MISC\n",
      "     Protocolo do Estado MISC\n",
      "     Paróquia de Santa Maria de Belém LOC\n",
      "     País LOC\n",
      "Entity not available\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(text)\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print(f\"     {ent.text} {ent.label_}\")\n",
    "else:\n",
    "    print(\"Entity not available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>lemma</th>\n",
       "      <th>pos</th>\n",
       "      <th>tag</th>\n",
       "      <th>dep</th>\n",
       "      <th>shape</th>\n",
       "      <th>is_alpha</th>\n",
       "      <th>is_stop</th>\n",
       "      <th>is_punctuation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>O</td>\n",
       "      <td>(O,)</td>\n",
       "      <td>DET</td>\n",
       "      <td>DET</td>\n",
       "      <td>det</td>\n",
       "      <td>X</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Real</td>\n",
       "      <td>(Real,)</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>Xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mosteiro</td>\n",
       "      <td>(Mosteiro,)</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>flat:name</td>\n",
       "      <td>Xxxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>de</td>\n",
       "      <td>(de,)</td>\n",
       "      <td>ADP</td>\n",
       "      <td>ADP</td>\n",
       "      <td>case</td>\n",
       "      <td>xx</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Santa</td>\n",
       "      <td>(Santa,)</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>nmod</td>\n",
       "      <td>Xxxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>mais</td>\n",
       "      <td>(mais,)</td>\n",
       "      <td>ADV</td>\n",
       "      <td>ADV</td>\n",
       "      <td>advmod</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>visitado</td>\n",
       "      <td>(visitar,)</td>\n",
       "      <td>VERB</td>\n",
       "      <td>VERB</td>\n",
       "      <td>acl</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>do</td>\n",
       "      <td>(do,)</td>\n",
       "      <td>ADP</td>\n",
       "      <td>ADP</td>\n",
       "      <td>case</td>\n",
       "      <td>xx</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>País</td>\n",
       "      <td>(País,)</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>obl</td>\n",
       "      <td>Xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>.</td>\n",
       "      <td>(.,)</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>punct</td>\n",
       "      <td>.</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>103 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         text        lemma    pos    tag        dep  shape is_alpha is_stop  \\\n",
       "0           O         (O,)    DET    DET        det      X     True    True   \n",
       "1        Real      (Real,)  PROPN  PROPN      nsubj   Xxxx     True   False   \n",
       "2    Mosteiro  (Mosteiro,)  PROPN  PROPN  flat:name  Xxxxx     True   False   \n",
       "3          de        (de,)    ADP    ADP       case     xx     True    True   \n",
       "4       Santa     (Santa,)  PROPN  PROPN       nmod  Xxxxx     True   False   \n",
       "..        ...          ...    ...    ...        ...    ...      ...     ...   \n",
       "98       mais      (mais,)    ADV    ADV     advmod   xxxx     True    True   \n",
       "99   visitado   (visitar,)   VERB   VERB        acl   xxxx     True   False   \n",
       "100        do        (do,)    ADP    ADP       case     xx     True    True   \n",
       "101      País      (País,)  PROPN  PROPN        obl   Xxxx     True   False   \n",
       "102         .         (.,)  PUNCT  PUNCT      punct      .    False   False   \n",
       "\n",
       "    is_punctuation  \n",
       "0            False  \n",
       "1            False  \n",
       "2            False  \n",
       "3            False  \n",
       "4            False  \n",
       "..             ...  \n",
       "98           False  \n",
       "99           False  \n",
       "100          False  \n",
       "101          False  \n",
       "102           True  \n",
       "\n",
       "[103 rows x 9 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for token in doc:\n",
    "#     print(token.text, token.lemma_, token.pos_, token.tag_, token.dep_,\n",
    "#             token.shape_, token.is_alpha, token.is_stop)\n",
    "\n",
    "\n",
    "tokenized_text = pd.DataFrame()\n",
    "\n",
    "for i, token in enumerate(doc):\n",
    "    tokenized_text.loc[i, 'text'] = token.text\n",
    "    tokenized_text.loc[i, 'lemma'] = token.lemma_,\n",
    "    tokenized_text.loc[i, 'pos'] = token.pos_\n",
    "    tokenized_text.loc[i, 'tag'] = token.tag_\n",
    "    tokenized_text.loc[i, 'dep'] = token.dep_\n",
    "    tokenized_text.loc[i, 'shape'] = token.shape_\n",
    "    tokenized_text.loc[i, 'is_alpha'] = token.is_alpha\n",
    "    tokenized_text.loc[i, 'is_stop'] = token.is_stop\n",
    "    tokenized_text.loc[i, 'is_punctuation'] = token.is_punct\n",
    "\n",
    "tokenized_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PORTUGUESE TWEETS ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"C:\\\\Test folder\\\\NoThemeTweets.csv\") as csv_file:\n",
    "    data = pd.read_csv(csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>tweet_date</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>query_used</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1031761728445530112</td>\n",
       "      <td>@Tixaa23 14 para eu ir :)</td>\n",
       "      <td>Tue Aug 21 04:35:39 +0000 2018</td>\n",
       "      <td>Positivo</td>\n",
       "      <td>:)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1031761040462278656</td>\n",
       "      <td>@drexalvarez O meu like eu já dei na época :)</td>\n",
       "      <td>Tue Aug 21 04:32:55 +0000 2018</td>\n",
       "      <td>Positivo</td>\n",
       "      <td>:)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1031760962372689920</td>\n",
       "      <td>Eu só queria conseguir comer alguma coisa pra ...</td>\n",
       "      <td>Tue Aug 21 04:32:37 +0000 2018</td>\n",
       "      <td>Positivo</td>\n",
       "      <td>:)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1031760948250456066</td>\n",
       "      <td>:D que lindo dia !</td>\n",
       "      <td>Tue Aug 21 04:32:33 +0000 2018</td>\n",
       "      <td>Positivo</td>\n",
       "      <td>:)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1031760895985246208</td>\n",
       "      <td>@Primo_Resmungao Pq da pr jeito!!é uma \"oferta...</td>\n",
       "      <td>Tue Aug 21 04:32:21 +0000 2018</td>\n",
       "      <td>Positivo</td>\n",
       "      <td>:)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id                                         tweet_text  \\\n",
       "0  1031761728445530112                          @Tixaa23 14 para eu ir :)   \n",
       "1  1031761040462278656      @drexalvarez O meu like eu já dei na época :)   \n",
       "2  1031760962372689920  Eu só queria conseguir comer alguma coisa pra ...   \n",
       "3  1031760948250456066                                 :D que lindo dia !   \n",
       "4  1031760895985246208  @Primo_Resmungao Pq da pr jeito!!é uma \"oferta...   \n",
       "\n",
       "                       tweet_date sentiment query_used  \n",
       "0  Tue Aug 21 04:35:39 +0000 2018  Positivo         :)  \n",
       "1  Tue Aug 21 04:32:55 +0000 2018  Positivo         :)  \n",
       "2  Tue Aug 21 04:32:37 +0000 2018  Positivo         :)  \n",
       "3  Tue Aug 21 04:32:33 +0000 2018  Positivo         :)  \n",
       "4  Tue Aug 21 04:32:21 +0000 2018  Positivo         :)  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(785814, 5)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "()"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ents = nlp.get_pipe('attribute_ruler').\n",
    "ents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('ROOT',\n",
       " 'acl',\n",
       " 'acl:relcl',\n",
       " 'advcl',\n",
       " 'advmod',\n",
       " 'amod',\n",
       " 'appos',\n",
       " 'aux',\n",
       " 'aux:pass',\n",
       " 'case',\n",
       " 'cc',\n",
       " 'ccomp',\n",
       " 'compound',\n",
       " 'conj',\n",
       " 'cop',\n",
       " 'csubj',\n",
       " 'dep',\n",
       " 'det',\n",
       " 'discourse',\n",
       " 'expl',\n",
       " 'fixed',\n",
       " 'flat',\n",
       " 'flat:foreign',\n",
       " 'flat:name',\n",
       " 'iobj',\n",
       " 'mark',\n",
       " 'nmod',\n",
       " 'nsubj',\n",
       " 'nsubj:pass',\n",
       " 'nummod',\n",
       " 'obj',\n",
       " 'obl',\n",
       " 'obl:agent',\n",
       " 'parataxis',\n",
       " 'punct',\n",
       " 'xcomp')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ents = nlp.get_pipe('parser').labels\n",
    "ents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "()"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ents = nlp.get_pipe('tok2vec').labels\n",
    "ents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                             @Tixaa23 14 para eu ir :)\n",
       "1         @drexalvarez O meu like eu já dei na época :)\n",
       "2     Eu só queria conseguir comer alguma coisa pra ...\n",
       "3                                    :D que lindo dia !\n",
       "4     @Primo_Resmungao Pq da pr jeito!!é uma \"oferta...\n",
       "                            ...                        \n",
       "95              @rihanney se você não for me ignorar :)\n",
       "96    Comeu eshilley né safado OKAISUWOSOKSSKSISSJS ...\n",
       "97      @beamarcelino Aleatórias não, bora construir :)\n",
       "98                                  Mas fui ao mc :))))\n",
       "99    vi sua namorada sem voce no role vcs terminara...\n",
       "Name: tweet_text, Length: 100, dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = data['tweet_text'][:100]\n",
    "tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = []\n",
    "type(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['@Tixaa23 14 para eu ir :)', '@drexalvarez O meu like eu já dei na época :)', 'Eu só queria conseguir comer alguma coisa pra poder dormir :)', ':D que lindo dia !', '@Primo_Resmungao Pq da pr jeito!!é uma \"oferta\", ha q aproveitar. :P', '@BadWolf_Wagner @DanieVedo Eu entendi, mas isso foi mais porque eu pensei em outra coisa. :P', '@Chyko661 @g1 [+] Carcinoma Hepatico (Cancer de Figado). Deivison lutou contra a doença por um ano e faleceu ontem a tarde. Espero que minha explicaçao tenha te ajudado. :)', 'Aquela mina da limpeza, que tinha um marido com meu problema me adicionou aqui no face, esquisito a princípio mas ah, nega velha e pa, veio perguntar como eu tô :) Ela deve ter tomado as dor, me viu malzao e pá.', '@narryfools aqui, espero que você melhore logo :) https://t.co/OBiMIrbU9F', '@fefocaires se és feliz trabalhando nisso então não pare se as pessoas se incomodam com sua opinião é pq elas te dão ouvido e seu trabalho tem um grande alcance :)', 'vamos se seguir no insta? se quiser sdv :) #TercaDetremuraSDV', '@youngsnowblood @thegr8angelica a para vc q é ♥️♥️ mt obg, eu me sinto até melhor agr :)', 'foo :) : 400e84d5-1e93-4d95-8280-2d99fc5bbb12', \"Quando você joga com um youtuber que você segue e nem percebe na hora rs. Hope I've beaten you mr. @Alex_Olney from @nintendolife :P https://t.co/FMnZCneQUa\", '@bebadoetriste é pra fazer torresmo :)', '@Calebe80781696 Vixe q treta novelesca! Que bom a amizade foi forte e vcs estão conectados ainda! :)))', 'Aqui lembrando o shade das donzelas. :) A Camila foi perguntanda em uma entrevista e disse que na hora estava em casa e ATÉ chorou vendo isso. https://t.co/HDIPdpaTgM', '@LelloucheNico Bravo ! :)', 'Gostei de um vídeo @YouTube https://t.co/FGEgHwa67q(🔴LIVE) FORTNITE DA NIGHT :D - LEOZERA - PC', 'Nenhum dos itens são meus. Tô só fazendo aquela divulgação :D SP tem preferência pra entrega em mãos, mas a gente faz uns Sedex aí e tal RT do amor pra chegar no próximo Faker!']\n"
     ]
    }
   ],
   "source": [
    "tweets = []\n",
    "for i in data['tweet_text'][:20]:\n",
    "    #print('working',  i)\n",
    "    tweets.append(i)\n",
    "print(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PER --> Carcinoma Hepatico\n",
      "PER --> Deivison\n",
      "PER --> @fefocaires\n",
      "PER --> A Camila\n",
      "PER --> ATÉ\n"
     ]
    }
   ],
   "source": [
    "# Merge noun phrases and entities for easier analysis\n",
    "# nlp.add_pipe(\"merge_entities\")\n",
    "# nlp.add_pipe(\"merge_noun_chunks\")\n",
    "\n",
    "for doc in nlp.pipe(tweets):\n",
    "    for token in doc:\n",
    "        if token.ent_type_ == \"PER\" or token.ent_type_ == \"ORG\":\n",
    "            print(token.ent_type_, \"-->\", token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in nlp.pipe(tweets):\n",
    "    for token in doc:\n",
    "        if token.ent_type_ in ents:\n",
    "            print(ents, \"-->\", token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "610efb86e122df48aab22117e29509e00a585e4642c6384735721f42f83ab1a2"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('projeto_apspacy')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
